{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kp-SwUVFk9R"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>SUTRA by TWO Platforms</h2>\n",
        "  <p>SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.</p>\n",
        "\n",
        "  <h1> AISuite</h1>\n",
        "  <p>AISuite is a unified interface for generative AI providers, allowing you to easily switch between different AI models and providers with minimal code changes. It provides a consistent API for working with various AI models, making it easier to integrate and experiment with different AI capabilities..</p>\n",
        "</div>\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1phv0BVdZACSObnwheTkWf-no4GQh31a5?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtlA0EDxZBz"
      },
      "source": [
        "# SUTRA With AISuite\n",
        "\n",
        "This notebook demonstrates how to use the Sutra model with AISuite, a unified interface for generative AI providers.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyXGuJbQGDIz"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZXgicSHxZB2"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "First, let's install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObbeupIvxZB2"
      },
      "outputs": [],
      "source": [
        "!pip install 'aisuite[openai]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykv4IeiNxZB3"
      },
      "source": [
        "## Setting up Environment Variables\n",
        "\n",
        "You'll need to set up your API keys. For security reasons, it's best to use environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hybwJE-lxZB3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"SUTRA_API_KEY\"] = userdata.get(\"SUTRA_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2tJdEsOxZB3"
      },
      "source": [
        "## Basic Usage of Sutra with AISuite\n",
        "\n",
        "Let's first see how to use Sutra with AISuite for basic completions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNUwH5B3xZB4",
        "outputId": "38849dc6-77ea-4e1e-d771-7a66be0a15f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, and understanding natural language. AI technologies can be categorized into narrow AI, which is designed for specific tasks, and general AI, which aims to perform any intellectual task that a human can do.\n"
          ]
        }
      ],
      "source": [
        "import aisuite as ai\n",
        "import os\n",
        "\n",
        "# Configure AISuite with SUTRA-V2\n",
        "provider_configs = {\n",
        "    \"openai\": {\n",
        "        \"api_key\": os.getenv(\"SUTRA_API_KEY\"),\n",
        "        \"base_url\": \"https://api.two.ai/v2\"\n",
        "    }\n",
        "}\n",
        "\n",
        "client = ai.Client(provider_configs)\n",
        "\n",
        "# Test a basic completion\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that specializes in Indian languages and culture.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain artificial intelligence in 3 sentences.\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"openai:sutra-v2\",\n",
        "    messages=messages,\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEc6gRoixZB4"
      },
      "source": [
        "## Multilingual Capabilities of Sutra\n",
        "\n",
        "One of Sutra's strengths is its multilingual capabilities. Let's test it with Hindi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V7ahKDhxZB4"
      },
      "outputs": [],
      "source": [
        "# Hindi example\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"आप एक सहायक AI हैं जो हिंदी में उत्तर देती है।\"},\n",
        "    {\"role\": \"user\", \"content\": \"भारतीय संस्कृति में गंगा नदी का क्या महत्व है?\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"openai:sutra-v2\",\n",
        "    messages=messages,\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGCpGBc3xZB4"
      },
      "source": [
        "## Streaming Responses with AISuite\n",
        "\n",
        "AISuite supports streaming responses, which is useful for real-time applications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs74eBK1xZB4"
      },
      "outputs": [],
      "source": [
        "# Stream a response\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a creative writer.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a short story about a robot discovering emotions.\"}\n",
        "]\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"openai:sutra-v2\",\n",
        "    messages=messages,\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices and chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end='', flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZBXrm8DxZB5"
      },
      "source": [
        "## Working with Different Parameter Settings\n",
        "\n",
        "Let's explore how different parameter settings affect Sutra's responses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhfbv_HoxZB5"
      },
      "outputs": [],
      "source": [
        "# Base prompt\n",
        "base_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a short poem about the monsoon season in India.\"}\n",
        "]\n",
        "\n",
        "# Test with different temperature settings\n",
        "print(\"Temperature = 0.3 (More focused):\\n\")\n",
        "response_low_temp = client.chat.completions.create(\n",
        "    model=\"openai:sutra-v2\",\n",
        "    messages=base_messages,\n",
        "    max_tokens=200,\n",
        "    temperature=0.3\n",
        ")\n",
        "print(response_low_temp.choices[0].message.content)\n",
        "\n",
        "print(\"\\n\\nTemperature = 0.9 (More creative):\\n\")\n",
        "response_high_temp = client.chat.completions.create(\n",
        "    model=\"openai:sutra-v2\",\n",
        "    messages=base_messages,\n",
        "    max_tokens=200,\n",
        "    temperature=0.9\n",
        ")\n",
        "print(response_high_temp.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiT9McqexZB6"
      },
      "source": [
        "## Practical Example: Building a Multilingual Q&A System\n",
        "\n",
        "Let's create a simple multilingual Q&A system using Sutra and AISuite:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzk4mfQqxZB6"
      },
      "outputs": [],
      "source": [
        "def multilingual_qa(question, language=\"english\"):\n",
        "    \"\"\"A simple multilingual Q&A function using Sutra and AISuite.\n",
        "\n",
        "    Args:\n",
        "        question (str): The question to ask\n",
        "        language (str): The language for the response (english, hindi, tamil, etc.)\n",
        "\n",
        "    Returns:\n",
        "        str: The response in the requested language\n",
        "    \"\"\"\n",
        "    # Language-specific system prompts\n",
        "    system_prompts = {\n",
        "        \"english\": \"You are a helpful assistant. Respond in English.\",\n",
        "        \"hindi\": \"आप एक सहायक AI हैं। कृपया हिंदी में उत्तर दें।\",\n",
        "        \"tamil\": \"நீங்கள் ஒரு உதவிகரமான AI ஆவீர்கள். தமிழில் பதிலளிக்கவும்.\",\n",
        "        \"bengali\": \"আপনি একজন সহায়ক AI। বাংলায় উত্তর দিন।\",\n",
        "        \"telugu\": \"మీరు సహాయకరమైన AI. దయచేసి తెలుగులో సమాధానం ఇవ్వండి.\",\n",
        "        \"marathi\": \"आपण एक सहाय्यक AI आहात. कृपया मराठीत उत्तर द्या.\",\n",
        "        \"punjabi\": \"ਤੁਸੀਂ ਇੱਕ ਸਹਾਇਕ AI ਹੋ। ਕਿਰਪਾ ਕਰਕੇ ਪੰਜਾਬੀ ਵਿੱਚ ਜਵਾਬ ਦਿਓ।\"\n",
        "    }\n",
        "\n",
        "    # Default to English if language not supported\n",
        "    system_prompt = system_prompts.get(language.lower(), system_prompts[\"english\"])\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"openai:sutra-v2\",\n",
        "        messages=messages,\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Test the multilingual Q&A system\n",
        "questions = [\n",
        "    (\"What are the major festivals celebrated in India?\", \"english\"),\n",
        "    (\"भारत के प्रमुख त्योहार कौन-कौन से हैं?\", \"hindi\"),\n",
        "    (\"இந்தியாவில் கொண்டாடப்படும் முக்கிய திருவிழாக்கள் யாவை?\", \"tamil\")\n",
        "]\n",
        "\n",
        "for question, language in questions:\n",
        "    print(f\"\\n\\n=== Question ({language}) ===\\n{question}\\n\")\n",
        "    print(f\"=== Response ===\\n{multilingual_qa(question, language)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAP9ycssxZB6"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've explored how to use Sutra with AISuite for various natural language processing tasks. We've covered:\n",
        "\n",
        "1. Basic setup and configuration\n",
        "2. Simple completions and chat interactions\n",
        "3. Multilingual capabilities\n",
        "4. Streaming responses\n",
        "6. Parameter tuning\n",
        "7. Building a practical multilingual Q&A system\n",
        "\n",
        "Sutra's multilingual capabilities make it particularly well-suited for applications targeting Indian languages and contexts, while AISuite provides a flexible and consistent interface for working with Sutra and potentially other AI models in your applications."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
